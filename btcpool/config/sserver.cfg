#
# stratum server cfg
#
# @since 2016-06
# @copyright btc.com
#

# is using testnet3
testnet = false;

kafka = {
  brokers = "kafka:9092";
};

zookeeper = {
  brokers = "zookeeper:2181";
};

sserver = {
  # serverType
  type = "CKB";
  
  ip = "0.0.0.0";
  port = 1800;

  # should be global unique, range: [1, 255]
  # If the id is 0, try to automatically assign one from zookeeper.
  id = 0;
  # The lock path used when automatically assigning an id
  zookeeper_lock_path = "/locks/sserver_ckb";

  # write last mining notify job send time to file, for monitor
  file_last_notify_time = "./sserver_lastnotifytime.txt";

  # the connection will be closed if the miner does not send any message
  # to the sserver within the specified seconds.
  tcp_read_timeout = 600;

  # how many seconds between two share submit
  share_avg_seconds = 10;

  # the lifetime of a job
  # It should not be too short, otherwise the valid share will be rejected due to job not found.
  max_job_lifetime = 300;

  # the job interval
  # sserver will push latest job if there are no new jobs for this interval
  mining_notify_interval = 30;

  # default difficulty (hex)
  default_difficulty = "65536";

  # max difficulty (hex)
  max_difficulty = "40000000000";

  # min difficulty (hex)
  min_difficulty = "2";

  # Adjust difficulty once every N second
  diff_adjust_period = 900;

  # When exiting, the connection will be closed gradually within the specified time.
  # Set to 0 to disable this feature.
  shutdown_grace_period = 3600;

  nicehash = {
    # Set to true if you want to force minimal difficulty for whole sserver
    forced = false;

    # Fallback value when ZooKeeper is not available
    min_difficulty = "10000";

    # Read NiceHash minimal difficulty from this ZooKeeper node
    min_difficulty_zookeeper_path = "/nicehash/sha256/min_difficulty"
  };
  
  #
  # version_mask, uint32_t
  #          2(0x00000002) : allow client change bit 1
  #         16(0x00000010) : allow client change bit 4
  #  536862720(0x1fffe000) : allow client change bit 13 to 28
  #
  #  version_mask = 0;
  #  version_mask = 16;
  #  version_mask = 536862720; // recommended, BIP9 security
  #  ...
  #
  version_mask = 536862720;

  # it could be 4 ~ 8
  # it should be 4 if you want proxy stratum jobs with poolwatcher(proxy).cfg
  extra_nonce2_size = 8;

  # Send ShareBitcoinBytesV1 to share_topic to keep compatibility with legacy statshttpd/sharelogger.
  use_share_v1 = false;
  
  # topics
  job_topic = "CkbJob";
  share_topic = "CkbShare";
  solved_share_topic = "CkSolvedShare";
  auxpow_solved_share_topic = "AuxSolvedShare"; # auxpow (eg. Namecoin) solved share topic
  rsk_solved_share_topic = "RskSolvedShare";
  common_events_topic = "CkbCommonEvents";

  # Accepting the PROXY Protocol to get the original IP of the miner from a proxy.
  # <https://docs.nginx.com/nginx/admin-guide/load-balancer/using-proxy-protocol/>
  proxy_protocol = false;

  ########################## dev options #########################

  # if enable simulator, all share will be accepted. for testing
  enable_simulator = false;

  # if enable it, all share will make block and submit. for testing
  enable_submit_invalid_block = false;

  # if enable, difficulty sent to miners is always dev_fixed_difficulty. for development
  enable_dev_mode = false;

  # difficulty to send to miners. for development
  dev_fixed_difficulty = 0.005;
  
  ###################### end of dev options ######################

  grandPoolEnabled = false; # default: false
};

users = {
  #
  # https://example.com/get_user_id_list?last_id=0
  # {"err_no":0,"err_msg":null,"data":{"jack":1,"terry":2}}
  #
  # There is a demo: https://github.com/btccom/btcpool/issues/16#issuecomment-278245381
  #
  list_id_api_url = "http://miner-list:8000/miner_list";

  # Make the user name case insensitive
  case_insensitive = true;

  # Enable single user mode.
  # In this mode, all sub-accounts connected to the sserver will become the worker name prefix for a specified user.
  # Example, a worker "user2.11x20" will become "user1.user2.11x20".
  #single_user_mode = false;
  #single_user_name = "user1";
  #single_user_puid = 1;
};

prometheus = {
  # whether prometheus exporter is enabled
  enabled = true
  # address for prometheus exporter to bind
  address = "0.0.0.0"
  # port for prometheus exporter to bind
  port = 9101
  # path of the prometheus exporter url
  path = "/metrics"
};

log = {
  # hide "client connect" log with the prefix
  #hide_ip_prefix = "100.122.";
};

management = {
  enabled = true; # default: true

  kafka_brokers = "kafka:9092"; # "10.0.0.1:9092,10.0.0.2:9092,..."
  controller_topic = "CkbManController";
  processor_topic = "CkbManProcessor";

  auto_switch_chain = false;
};

# Share jobs with the main pool, but with different coinbase information and addresses.
subpool = {
  enabled = false; # default: false
  name = "pool2";
  ext_user_id = -2; # Optional, reserved for data analysis. It should < 0 (preventing it is no different from single-user mode).
};

blockmaker = {
  type = "CKB";
};
#
# pool mysql db: table.found_blocks
#
pooldb = {
  host = "mysql";
  port = 3306;
  username = "root";
  password = "root";
  dbname = "BTCPOOL_CKB";
};

blk_makers = (
  {
    chain_type = "CKB"; //blockchain short name
    enabled = true; //enable worker
    nodes = (
      {
        rpc_addr = "http://ckb-node:8114";
        rpc_userpwd = "user:pass";
      }
    );
    # kafka topics
    rawgbt_topic = "CkbRawGbt";
    solved_share_topic = "CkbSolvedShare";
    auxpow_solved_share_topic = "AuxSolvedShare";
    rsk_solved_share_topic = "RskSolvedShare";
    job_topic = "CkbJob";

    # mysql table names
    found_aux_block_table = "found_nmc_blocks";
    #aux_chain_name indicate current mergemining chain name
    #aux means that unknown chain name or many chain aux-mining the same time 
    #doge means current only mergemining with dogecoin
    aux_chain_name = "aux";
  }
);

job_workers = (
  {
    chain_type = "CKB";
    # chain_name = "FOUNDATION";
    testnet = false;
    enabled = true;

    rawgw_topic = "CkbRawGw";
    job_topic = "CkbJob";

    id = 1;
    job_interval = 20; # as a backup // send stratum job interval (seconds)
    max_job_delay = 20; // max job dealy (seconds)
    work_life_time = 60; // max getWork life cycle time (seconds)


    zookeeper_lock_path = "/locks/jobmaker_ckb";
    file_last_job_time = "/work/btcpool/build/run_jobmaker/lastjobtime.txt";

    # block version, default is 0 means use the version which returned by bitcoind
    # or you can specify the version you want to signal.
    # more info: https://github.com/bitcoin/bips/blob/master/bip-0009.mediawiki
    # Example:
    #                      0 : use bitcoind block version (recommented)
    #  536870912(0x20000000) : bip9 support (with empty version bits)
    #  536870914(0x20000002) : bip141(segwit), bit 1
    #  536870928(0x20000010) : bip91, bit 4
    #  536870930(0x20000012) : bip141 & bip91, both bit 1 & 4
    #
    #  block_version = 0;
    #  block_version = 536870912;
    #  ...
    #
    block_version = 0;

    # payout address
    # payout_address = "0xEEa5B82B61424dF8020f5feDD81767f2d0D25Bfb";
    # coinbase info with location ID (https://github.com/btccom/btcpool/issues/36)
    coinbase_info = "/BTC.COM/";

  }
);

slparserhttpd = {
  ip = "0.0.0.0";
  port = 8081;

  # interval seconds, flush stats data into database
  # it's very fast because we use insert statement with multiple values and
  # merge table when flush data to DB. we have test mysql, it could flush
  # 50,000 itmes into DB in about 2.5 seconds.
  flush_db_interval = 15;
};

sharelog = {
  chain_type = "CKB";
  data_dir = "/work/btcpool/data";
  rpcurl = "http://ckb-node:8114";//get blockreward from ckb-node
  max_elements_num = 50000;//
};

statshttpd = {
  chain_type = "CKB";
  share_topic = "CkbShareLog";

  # common events topic
  # example: miner connected, miner disconnected, ...
  common_events_topic = "CkbCommonEvents";

  ip = "0.0.0.0";
  port = 8080;

  # interval seconds, flush workers data into database
  # it's very fast because we use insert statement with multiple values and
  # merge table when flush data to DB. we have test mysql, it could flush
  # 25,000 workers into DB in about 1.7 seconds.
  flush_db_interval = 15;
  # write last db flush time to file
  file_last_flush_time = "/work/btcpool/build/run_statshttpd/statshttpd_lastflushtime.txt";

  # write mining workers' info to mysql database
  use_mysql = true;
  # write mining workers' info to redis
  use_redis = false;
};

gbtmaker = {
  # rpc call interval seconds
  rpcinterval = 10;

  # check zmq when startup
  is_check_zmq = true;

  rawgbt_topic = "CkbRawGbt";

  # use RPC `getblocktemplatelight`, only for bch
  lightgbt = false; # if unspecified, default false
};

bitcoind = {
  # bitcoind MUST with zmq options: -zmqpubhashblock, -zmqpubhashtx
  # '-zmqpubhashtx' will use to check zmq is working when startup gbtmaker
  zmq_addr = "tcp://127.0.0.1:8331";
  # reconnect if no new messages are received after the following number of seconds
  zmq_timeout = 1200;

  # rpc settings
  rpc_addr    = "http://ckb-node:8114";
  rpc_userpwd = "user:pass";
};
